"""
Service de r√©cup√©ration de l'historique des ordres Hyperliquid
Version Service Continu - G√©n√®re des fichiers JSON toutes les X minutes
AVEC TOUS LES STATUTS : open, filled, canceled, rejected, etc.

‚úÖ AM√âLIORATIONS:
- Timeout augment√© pour ordres ouverts (60s au lieu de 30s)
- Pr√©servation des fichiers JSON en cas d'erreur de timeout
- Meilleure gestion des erreurs r√©seau
"""

from hyperliquid.info import Info
from hyperliquid.utils import constants
from datetime import datetime
import json
import time
import threading
import os
import sys
from dotenv import load_dotenv


class HyperliquidHistoryService:
    """Service qui r√©cup√®re p√©riodiquement l'historique des ordres"""
    
    def __init__(self, config_file: str = '.env'):
        """
        Initialise le service
        
        Args:
            config_file: Chemin vers le fichier .env
        """
        # Charger les variables d'environnement
        load_dotenv(config_file)
        
        # Configuration
        self.user_address = os.getenv('WALLET_ADDRESS')
        if not self.user_address or self.user_address == '0x...':
            raise ValueError("WALLET_ADDRESS non configur√© dans .env")
        
        # Intervalle de v√©rification (en minutes)
        self.check_interval_minutes = float(os.getenv('MIN_CHECK_INTERVAL_MINUTES', 10))
        
        # Dossier de sortie
        self.output_dir = 'log'
        
        # Cr√©er le dossier log s'il n'existe pas
        os.makedirs(self.output_dir, exist_ok=True)
        
        # √âtat du service
        self.running = False
        self.thread = None
        
        # Initialiser l'API Hyperliquid avec timeout
        self.info = Info(constants.MAINNET_API_URL, skip_ws=True)
        
        # Configurer un timeout pour les requ√™tes
        if hasattr(self.info, 'session'):
            # Le SDK utilise requests.Session
            import requests
            self.info.session = requests.Session()
            # Adapter avec timeout par d√©faut
            adapter = requests.adapters.HTTPAdapter(
                max_retries=3,
                pool_connections=10,
                pool_maxsize=10
            )
            self.info.session.mount('http://', adapter)
            self.info.session.mount('https://', adapter)
        
        # Mapping des paires spot
        self.spot_mapping = {}
        
        # Statistiques pour monitoring
        self.last_fetch_stats = {
            'open_orders_success': True,
            'historical_orders_success': True,
            'fills_success': True,
            'last_fetch_time': None
        }
        
        print(f"üìã Service initialis√©")
        print(f"   Adresse: {self.user_address}")
        print(f"   Intervalle: {self.check_interval_minutes} minutes")
        print(f"   Dossier sortie: {self.output_dir}/")
    
    def start(self):
        """D√©marre le service en arri√®re-plan"""
        if self.running:
            print("‚ö†Ô∏è  Service d√©j√† en cours d'ex√©cution")
            return
        
        print("\n" + "="*80)
        print("üöÄ D√âMARRAGE DU SERVICE D'HISTORIQUE HYPERLIQUID")
        print("="*80)
        
        self.running = True
        self.thread = threading.Thread(target=self._service_loop, daemon=True, name="HistoryService")
        self.thread.start()
        
        print("‚úÖ Service d√©marr√©")
        print(f"üìä Fichiers JSON g√©n√©r√©s toutes les {self.check_interval_minutes} minutes")
        print("="*80 + "\n")
    
    def stop(self):
        """Arr√™te le service"""
        if not self.running:
            return
        
        print("\nüõë Arr√™t du service...")
        self.running = False
        
        if self.thread and self.thread.is_alive():
            self.thread.join(timeout=5)
        
        print("‚úÖ Service arr√™t√©\n")
    
    def _service_loop(self):
        """Boucle principale du service"""
        # Charger les m√©tadonn√©es spot une seule fois
        try:
            self._load_spot_metadata()
        except Exception as e:
            print(f"‚ùå Erreur chargement m√©tadonn√©es: {e}")
            self.running = False
            return
        
        while self.running:
            try:
                print(f"\n{'='*80}")
                print(f"üîÑ R√âCUP√âRATION HISTORIQUE - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                print("="*80)
                
                start_time = time.time()
                
                # R√©cup√©rer les donn√©es avec flags de succ√®s
                data, success_flags = self._fetch_complete_history()
                
                # Mettre √† jour les stats
                self.last_fetch_stats.update(success_flags)
                self.last_fetch_stats['last_fetch_time'] = datetime.now()
                
                # Exporter vers JSON (en pr√©servant les anciens fichiers si √©chec)
                self._export_to_json(data, success_flags)
                
                elapsed = time.time() - start_time
                print(f"\n‚úÖ R√©cup√©ration termin√©e en {elapsed:.1f}s")
                
                # Afficher les warnings si certaines r√©cup√©rations ont √©chou√©
                if not all(success_flags.values()):
                    print("\n‚ö†Ô∏è  AVERTISSEMENT: Certaines donn√©es n'ont pas pu √™tre r√©cup√©r√©es:")
                    if not success_flags.get('open_orders_success'):
                        print("   ‚Ä¢ Ordres ouverts: √âCHEC (ancien fichier pr√©serv√©)")
                    if not success_flags.get('historical_orders_success'):
                        print("   ‚Ä¢ Historique: √âCHEC")
                    if not success_flags.get('fills_success'):
                        print("   ‚Ä¢ Fills: √âCHEC")
                
                print("="*80)
                
                # Attendre avant la prochaine r√©cup√©ration
                wait_seconds = self.check_interval_minutes * 60
                print(f"\n‚è≥ Prochaine r√©cup√©ration dans {self.check_interval_minutes} minutes...")
                
                # Attendre par intervalles de 30s pour pouvoir arr√™ter proprement
                elapsed_wait = 0
                while elapsed_wait < wait_seconds and self.running:
                    time.sleep(min(30, wait_seconds - elapsed_wait))
                    elapsed_wait += 30
                
            except Exception as e:
                print(f"\n‚ùå Erreur dans le service: {e}")
                import traceback
                traceback.print_exc()
                
                # Attendre 60s avant de r√©essayer
                time.sleep(60)
    
    def _load_spot_metadata(self):
        """Charge les m√©tadonn√©es des paires Spot"""
        print("\nüìñ Chargement des m√©tadonn√©es Spot...")
        
        spot_meta = self.info.spot_meta()
        
        for idx, token_pair in enumerate(spot_meta['universe']):
            self.spot_mapping[f"@{idx}"] = token_pair['name']
        
        print(f"   ‚úÖ {len(self.spot_mapping)} paires charg√©es")
    
    def _fetch_complete_history(self):
        """
        R√©cup√®re l'historique COMPLET des ordres avec timeout am√©lior√©
        
        Returns:
            tuple: (data_dict, success_flags_dict)
            - data_dict: {
                'open_orders': [...],
                'historical_orders': [...],
                'fills': [...]
            }
            - success_flags_dict: {
                'open_orders_success': bool,
                'historical_orders_success': bool,
                'fills_success': bool
            }
        """
        # ‚úÖ TIMEOUT AUGMENT√â pour ordres ouverts qui timeout souvent
        TIMEOUT_OPEN_ORDERS = 60  # 60 secondes pour ordres ouverts
        TIMEOUT_STANDARD = 30     # 30 secondes pour le reste
        
        # Flags de succ√®s
        success_flags = {
            'open_orders_success': False,
            'historical_orders_success': False,
            'fills_success': False
        }
        
        try:
            # =====================================
            # 1. ORDRES OUVERTS (timeout augment√© + retry)
            # =====================================
            print("\nüì• 1/3 - R√©cup√©ration des ordres ouverts...")
            open_orders = []
            max_retries = 3
            
            for attempt in range(max_retries):
                try:
                    # ‚úÖ FIX: Cr√©er un nouvel objet Info √† chaque tentative
                    info = Info(constants.MAINNET_API_URL, skip_ws=True)
                    
                    # ‚úÖ Timeout sp√©cial pour ordres ouverts
                    original_timeout = getattr(info, 'timeout', None)
                    info.timeout = TIMEOUT_OPEN_ORDERS
                    
                    print(f"   üì° Tentative {attempt + 1}/{max_retries} (timeout: {TIMEOUT_OPEN_ORDERS}s)...")
                    open_orders = info.open_orders(self.user_address)
                    
                    # Restaurer timeout original
                    if original_timeout is not None:
                        info.timeout = original_timeout
                    
                    # ‚úÖ Succ√®s - sortir de la boucle
                    success_flags['open_orders_success'] = True
                    break
                    
                except (ConnectionResetError, ConnectionError, TimeoutError) as e:
                    if attempt < max_retries - 1:
                        print(f"   ‚ö†Ô∏è  Erreur r√©seau, r√©essai dans 3s...")
                        time.sleep(3)
                    else:
                        print(f"   ‚ùå √âchec apr√®s {max_retries} tentatives: {type(e).__name__}")
                        print(f"      Message: {str(e)[:100]}")
                        open_orders = []
                        success_flags['open_orders_success'] = False
                        
                except Exception as e:
                    print(f"   ‚ùå Erreur ordres ouverts: {type(e).__name__}: {str(e)[:100]}")
                    open_orders = []
                    success_flags['open_orders_success'] = False
                    break
            
            spot_open_orders = [order for order in open_orders if order.get('coin', '').startswith('@')]
            
            if success_flags['open_orders_success']:
                print(f"   ‚úÖ {len(spot_open_orders)} ordres Spot ouverts")
            else:
                print(f"   ‚ö†Ô∏è  0 ordres Spot ouverts (√©chec r√©cup√©ration)")
            
            # =====================================
            # 2. HISTORIQUE COMPLET
            # =====================================
            print("\nüì• 2/3 - R√©cup√©ration de l'historique complet...")
            historical_orders = []
            
            for attempt in range(max_retries):
                try:
                    # ‚úÖ FIX: Cr√©er un nouvel objet Info √† chaque tentative
                    info = Info(constants.MAINNET_API_URL, skip_ws=True)
                    info.timeout = TIMEOUT_STANDARD
                    
                    historical_orders = info.post("/info", {
                        "type": "historicalOrders",
                        "user": self.user_address
                    })
                    
                    if original_timeout is not None:
                        info.timeout = original_timeout
                    
                    # ‚úÖ Succ√®s
                    success_flags['historical_orders_success'] = True
                    break
                    
                except (ConnectionResetError, ConnectionError, TimeoutError) as e:
                    if attempt < max_retries - 1:
                        print(f"   ‚ö†Ô∏è  Tentative {attempt + 1}/{max_retries} √©chou√©e, r√©essai dans 2s...")
                        time.sleep(2)
                    else:
                        print(f"   ‚ùå Erreur historique apr√®s {max_retries} tentatives: {type(e).__name__}")
                        historical_orders = []
                        success_flags['historical_orders_success'] = False
                        
                except Exception as e:
                    print(f"   ‚ùå Erreur historique: {type(e).__name__}")
                    historical_orders = []
                    success_flags['historical_orders_success'] = False
                    break
            
            spot_historical = [order for order in historical_orders 
                              if order.get('order', {}).get('coin', '').startswith('@')]
            print(f"   ‚úÖ {len(spot_historical)} ordres Spot historiques")
            
            # =====================================
            # 3. FILLS
            # =====================================
            print("\nüì• 3/3 - R√©cup√©ration des fills...")
            fills = []
            
            for attempt in range(max_retries):
                try:
                    # ‚úÖ FIX: Cr√©er un nouvel objet Info √† chaque tentative
                    info = Info(constants.MAINNET_API_URL, skip_ws=True)
                    info.timeout = TIMEOUT_STANDARD
                    
                    fills = info.user_fills(self.user_address)
                    
                    if original_timeout is not None:
                        info.timeout = original_timeout
                    
                    # ‚úÖ Succ√®s
                    success_flags['fills_success'] = True
                    break
                    
                except (ConnectionResetError, ConnectionError, TimeoutError) as e:
                    if attempt < max_retries - 1:
                        print(f"   ‚ö†Ô∏è  Tentative {attempt + 1}/{max_retries} √©chou√©e, r√©essai dans 2s...")
                        time.sleep(2)
                    else:
                        print(f"   ‚ùå Erreur fills apr√®s {max_retries} tentatives: {type(e).__name__}")
                        fills = []
                        success_flags['fills_success'] = False
                        
                except Exception as e:
                    print(f"   ‚ùå Erreur fills: {type(e).__name__}")
                    fills = []
                    success_flags['fills_success'] = False
                    break
            
            spot_fills = [fill for fill in fills if fill.get('coin', '').startswith('@')]
            print(f"   ‚úÖ {len(spot_fills)} fills Spot")
            
            # D√©coder les noms de paires
            self._decode_orders(spot_open_orders)
            self._decode_orders(spot_historical)
            
            data = {
                'open_orders': spot_open_orders,
                'historical_orders': spot_historical,
                'fills': spot_fills
            }
            
            return data, success_flags
            
        except Exception as e:
            print(f"‚ùå Erreur r√©cup√©ration historique: {e}")
            import traceback
            traceback.print_exc()
            
            # En cas d'erreur, retourner des listes vides avec tous les flags √† False
            return {
                'open_orders': [],
                'historical_orders': [],
                'fills': []
            }, {
                'open_orders_success': False,
                'historical_orders_success': False,
                'fills_success': False
            }
    
    def _decode_orders(self, orders):
        """D√©code les noms de paires dans les ordres"""
        for order_data in orders:
            if 'order' in order_data:
                order = order_data['order']
            else:
                order = order_data
            
            coin = order.get('coin', '')
            if coin.startswith('@'):
                order['coin_name'] = self.spot_mapping.get(coin, coin)
            else:
                order['coin_name'] = coin
    
    def _export_to_json(self, data, success_flags):
        """
        Exporte les donn√©es dans 3 fichiers JSON dans /log
        
        ‚úÖ NOUVEAU: Pr√©serve les anciens fichiers si la r√©cup√©ration a √©chou√©
        
        Args:
            data: dict avec open_orders, historical_orders, fills
            success_flags: dict avec les flags de succ√®s pour chaque type
        """
        timestamp = datetime.now().isoformat()
        
        try:
            # =====================================
            # 1. OPEN_ORDERS.JSON
            # ‚ö†Ô∏è  N'√©craser QUE si la r√©cup√©ration a r√©ussi
            # =====================================
            if success_flags.get('open_orders_success', False):
                open_orders_path = os.path.join(self.output_dir, 'open_orders.json')
                open_orders_data = {
                    'generated_at': timestamp,
                    'user_address': self.user_address,
                    'count': len(data['open_orders']),
                    'orders': data['open_orders'],
                    'fetch_success': True
                }
                
                with open(open_orders_path, 'w', encoding='utf-8') as f:
                    json.dump(open_orders_data, f, indent=2, ensure_ascii=False, default=str)
                
                print(f"\nüìÑ {open_orders_path}")
                print(f"   ‚úÖ {len(data['open_orders'])} ordres ouverts")
            else:
                # ‚úÖ PR√âSERVER l'ancien fichier en cas d'√©chec
                open_orders_path = os.path.join(self.output_dir, 'open_orders.json')
                
                if os.path.exists(open_orders_path):
                    print(f"\nüìÑ {open_orders_path}")
                    print(f"   ‚ö†Ô∏è  Fichier PR√âSERV√â (√©chec r√©cup√©ration)")
                    
                    # Optionnel: Marquer que les donn√©es sont anciennes
                    try:
                        with open(open_orders_path, 'r', encoding='utf-8') as f:
                            old_data = json.load(f)
                        
                        # Ajouter un flag pour indiquer que les donn√©es sont potentiellement obsol√®tes
                        old_data['last_failed_fetch'] = timestamp
                        old_data['fetch_success'] = False
                        
                        with open(open_orders_path, 'w', encoding='utf-8') as f:
                            json.dump(old_data, f, indent=2, ensure_ascii=False, default=str)
                        
                        print(f"   ‚ÑπÔ∏è  Marqu√© comme potentiellement obsol√®te")
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è  Impossible de mettre √† jour le flag: {e}")
                else:
                    print(f"\nüìÑ {open_orders_path}")
                    print(f"   ‚ö†Ô∏è  Fichier n'existe pas encore (premi√®re r√©cup√©ration √©chou√©e)")
            
            # =====================================
            # 2. FILLED_ORDERS.JSON
            # =====================================
            filled_orders_path = os.path.join(self.output_dir, 'filled_orders.json')
            filled_orders = [
                order for order in data['historical_orders']
                if order.get('status') == 'filled'
            ]
            
            filled_orders_data = {
                'generated_at': timestamp,
                'user_address': self.user_address,
                'count': len(filled_orders),
                'orders': filled_orders,
                'fills_details': data['fills'],
                'fetch_success': success_flags.get('historical_orders_success', False) and success_flags.get('fills_success', False)
            }
            
            with open(filled_orders_path, 'w', encoding='utf-8') as f:
                json.dump(filled_orders_data, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"\nüìÑ {filled_orders_path}")
            print(f"   ‚úÖ {len(filled_orders)} ordres ex√©cut√©s")
            
            # =====================================
            # 3. HISTORIC.JSON
            # =====================================
            historic_path = os.path.join(self.output_dir, 'historic.json')
            historic_data = {
                'generated_at': timestamp,
                'user_address': self.user_address,
                'summary': {
                    'total_orders': len(data['historical_orders']),
                    'open_orders': len([o for o in data['historical_orders'] if o.get('status') == 'open']),
                    'filled_orders': len([o for o in data['historical_orders'] if o.get('status') == 'filled']),
                    'canceled_orders': len([o for o in data['historical_orders'] if o.get('status') == 'canceled']),
                    'rejected_orders': len([o for o in data['historical_orders'] if o.get('status') == 'rejected']),
                },
                'orders': data['historical_orders'],
                'fetch_success': success_flags.get('historical_orders_success', False)
            }
            
            with open(historic_path, 'w', encoding='utf-8') as f:
                json.dump(historic_data, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"\nüìÑ {historic_path}")
            print(f"   ‚úÖ {len(data['historical_orders'])} ordres (tous statuts)")
            
        except Exception as e:
            print(f"\n‚ùå Erreur export JSON: {e}")
            import traceback
            traceback.print_exc()
    
    def fetch_now(self):
        """Force une r√©cup√©ration imm√©diate (pour tests)"""
        print("\nüîÑ R√©cup√©ration forc√©e...")
        
        try:
            if not self.spot_mapping:
                self._load_spot_metadata()
            
            data, success_flags = self._fetch_complete_history()
            
            # Exporter m√™me si certaines r√©cup√©rations ont √©chou√©
            self._export_to_json(data, success_flags)
            
            # V√©rifier si au moins une r√©cup√©ration a r√©ussi
            if any(success_flags.values()):
                print("\n‚úÖ R√©cup√©ration forc√©e termin√©e")
                if not all(success_flags.values()):
                    print("‚ö†Ô∏è  Certaines donn√©es n'ont pas pu √™tre r√©cup√©r√©es (voir ci-dessus)")
                return True
            else:
                print("\n‚ö†Ô∏è  √âchec complet de la r√©cup√©ration (timeout ou erreur r√©seau)")
                print("   V√©rifiez votre connexion r√©seau")
                return False
                
        except Exception as e:
            print(f"\n‚ùå Erreur: {e}")
            print("   V√©rifiez votre connexion √† api.hyperliquid.xyz")
            import traceback
            traceback.print_exc()
            return False
    
    def get_stats(self):
        """Retourne les statistiques de la derni√®re r√©cup√©ration"""
        return self.last_fetch_stats.copy()


def main():
    """Fonction principale pour ex√©cution standalone"""
    print("\nüöÄ Hyperliquid History Service - Mode Standalone")
    print("="*80)
    
    try:
        # Cr√©er et d√©marrer le service
        service = HyperliquidHistoryService()
        service.start()
        
        # Attendre ind√©finiment (Ctrl+C pour arr√™ter)
        print("\nüí° Appuyez sur Ctrl+C pour arr√™ter le service\n")
        
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interruption utilisateur")
        if 'service' in locals():
            service.stop()
        
    except Exception as e:
        print(f"\n‚ùå Erreur fatale: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()


"""
üì¶ Installation :
pip install hyperliquid-python-sdk python-dotenv

üöÄ Utilisation :

1. MODE SERVICE (int√©gr√© au bot) :
   from command.hyperliquid_complete_history import HyperliquidHistoryService
   
   service = HyperliquidHistoryService()
   service.start()  # D√©marre en arri√®re-plan

2. MODE STANDALONE (test) :
   python command/hyperliquid_complete_history.py

üìä Fichiers g√©n√©r√©s dans /log :
   - open_orders.json : Ordres actuellement ouverts
   - filled_orders.json : Ordres ex√©cut√©s + d√©tails fills
   - historic.json : Historique complet (tous statuts)

‚öôÔ∏è  Configuration (.env) :
   - WALLET_ADDRESS : Adresse du wallet (obligatoire)
   - MIN_CHECK_INTERVAL_MINUTES : Intervalle entre r√©cup√©rations (d√©faut: 10)

üîÑ Fonctionnement :
   - R√©cup√®re l'historique toutes les X minutes
   - G√©n√®re 3 fichiers JSON √† chaque fois
   - Les autres modules lisent ces JSON pour synchroniser

‚úÖ AM√âLIORATIONS v2:
   - Timeout augment√© pour ordres ouverts: 60s (au lieu de 30s)
   - Pr√©servation des fichiers JSON en cas d'√©chec de r√©cup√©ration
   - Meilleure gestion des erreurs r√©seau avec retry am√©lior√©
   - Flag de succ√®s pour chaque type de donn√©es
   - Marquage des donn√©es potentiellement obsol√®tes

‚ö†Ô∏è  Notes :
   - Maximum 2000 ordres historiques par r√©cup√©ration
   - Les JSON sont √©cras√©s seulement si la r√©cup√©ration r√©ussit
   - Le service tourne en daemon thread (ne bloque pas l'arr√™t du bot)
   - En cas de timeout, l'ancien fichier open_orders.json est pr√©serv√©
"""
